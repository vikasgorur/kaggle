{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import parser\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, scale\n",
    "from sklearn import metrics\n",
    "\n",
    "import sklearn.utils\n",
    "\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minute_of_day(row):\n",
    "    d = parser.parse(row[\"Dates\"])\n",
    "    return d.hour*60 + d.minute\n",
    "\n",
    "def day_number(row):\n",
    "    \"absolute number of days since 1/1/2000\"\n",
    "    d = parser.parse(row[\"Dates\"])\n",
    "    return (d.year - 2000)*365 + d.month * 30 + d.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    \"Read the filename and return X and y suitable for learning\"\n",
    "    t = pd.read_csv(filename)\n",
    "    v = DictVectorizer(sparse=False)\n",
    "\n",
    "    district = v.fit_transform(t[[\"PdDistrict\"]].T.to_dict().values())\n",
    "    day_of_week = v.fit_transform(t[[\"DayOfWeek\"]].T.to_dict().values())\n",
    "    min_of_day = t.apply(minute_of_day, axis='columns')\n",
    "    day = t.apply(day_number, axis='columns')\n",
    "    x = t[[\"X\"]]\n",
    "    y = t[[\"Y\"]]\n",
    "    \n",
    "    category = None\n",
    "    if 'Category' in t.columns:\n",
    "        le = LabelEncoder()\n",
    "        category = le.fit_transform(t[[\"Category\"]].values.ravel())\n",
    "        \n",
    "    dataset = {\n",
    "        'district': district,\n",
    "        'day_of_week': day_of_week,\n",
    "        'min_of_day': min_of_day,\n",
    "        'day': day,\n",
    "        'x': x,\n",
    "        'y': y,\n",
    "        'category': category\n",
    "    }\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = preprocess(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"train.pickle\", \"wb\") as f:\n",
    "    pickle.dump(train, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "Now that we have the data in a convenient format, let's train the model.\n",
    "\n",
    "First, let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = None\n",
    "with open(\"train.pickle\", \"rb\") as f:\n",
    "    train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose the features we want and construct the X and y matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikas/workspace/scikit-learn/sklearn/utils/validation.py:431: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning_)\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack((scale(train['day']), scale(train['min_of_day']), train['district'], train['day_of_week']))\n",
    "y = train['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a subset of the data to play around with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = 100000\n",
    "X, y = sklearn.utils.shuffle(X, y)\n",
    "X_small = X[0:train_size,]\n",
    "y_small = y[0:train_size,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 19)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:train_size,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = cross_validation.train_test_split(X_small, y_small, test_size=0.3, random_state=4)\n",
    "\n",
    "lg = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "model = lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_predict = model.predict_proba(X_train)\n",
    "y_valid_predict = model.predict_proba(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 38)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_valid)), y_valid_predict.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.5873\n",
      "Validation loss: 2.5976\n"
     ]
    }
   ],
   "source": [
    "print('Training loss: {0:.5}'.format(metrics.log_loss(y_train, y_train_predict)))\n",
    "print('Validation loss: {0:.5}'.format(metrics.log_loss(y_valid, y_valid_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result submission\n",
    "\n",
    "Let's use the model we trained to make predictions on the test data and prepare it for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test, _ = preprocess(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = np.arange(0, y_pred.shape[0], dtype='int32')\n",
    "submission = pd.concat([pd.DataFrame(ids, dtype='int32', columns=['Id']),\n",
    "                        pd.DataFrame(y_pred, columns=[\n",
    "            'ARSON', 'ASSAULT', 'BAD CHECKS', 'BRIBERY', 'BURGLARY',\n",
    "            'DISORDERLY CONDUCT', 'DRIVING UNDER THE INFLUENCE', 'DRUG/NARCOTIC',\n",
    "            'DRUNKENNESS', 'EMBEZZLEMENT', 'EXTORTION', 'FAMILY OFFENSES',\n",
    "            'FORGERY/COUNTERFEITING', 'FRAUD', 'GAMBLING', 'KIDNAPPING',\n",
    "            'LARCENY/THEFT', 'LIQUOR LAWS', 'LOITERING', 'MISSING PERSON',\n",
    "            'NON-CRIMINAL', 'OTHER OFFENSES', 'PORNOGRAPHY/OBSCENE MAT',\n",
    "            'PROSTITUTION', 'RECOVERED VEHICLE', 'ROBBERY', 'RUNAWAY',\n",
    "            'SECONDARY CODES', 'SEX OFFENSES FORCIBLE', 'SEX OFFENSES NON FORCIBLE',\n",
    "            'STOLEN PROPERTY', 'SUICIDE', 'SUSPICIOUS OCC', 'TREA', 'TRESPASS',\n",
    "            'VANDALISM', 'VEHICLE THEFT', 'WARRANTS', 'WEAPON LAWS'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission-1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
